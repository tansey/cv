\documentclass[10pt]{article}
\usepackage{natbib, array, xcolor, lipsum, bibentry, hyperref}
\usepackage[margin=2cm]{geometry}
\usepackage{longtable}


\title{\bfseries\Huge {Wesley Tansey}}
\author{wt2274@cumc.columbia.edu\hspace{200pt}(804)-867-5306\\\texttt{wesleytansey.com}\hspace{100pt}302A W 121st St Apt 3, New York, NY}
\date{}
\definecolor{lightgray}{gray}{0.8}
\newcolumntype{L}{>{\raggedleft}p{0.14\textwidth}}
\newcolumntype{R}{p{0.8\textwidth}}
\newcommand\VRule{\color{lightgray}\vrule width 0.5pt}

\begin{document}
\maketitle

%\vspace{20pt}
% \section*{Research Statement}
% \begin{tabular}{L!{\VRule}R}
% &

% I'm a Computer Science PhD candidate at UT Austin. My main research interests are health and wellness applications of machine learning, particularly those involving graphical models, Bayesian statistical methods, and scalable inference algorithms. My current projects include obesity and nutrition modeling, wearable devices for fitness tracking, and large-scale multiple hypothesis testing for fMRI and allele frequency studies. I am passionate about taking my research into the real world and am continually looking for new opportunities to collaborate with tech startups wishing to improve the lives of their users.
% \end{tabular}

\section*{Education}
\begin{tabular}{L!{\VRule}R}
2011--2017&{\bf PhD in Computer Science, University of Texas at Austin}\\
% 			& {\bf Graduate Coursework:}\\
% &{\it Graphical Models, Neural Networks, Bayesian Statistical Methods,},\\
% & {\it Natural Language Processing, Reinforcement Learning, Statistical Modeling II,}\\
% & {\it MCMC Methods, Mathematical Logic, Computer Security, Programming Languages}\\
2006--2008&{\bf MS in Computer Science, Virginia Tech}\\ %& GPA 3.81\\
2003--2006&{\bf BS in Computer Science, Virginia Tech}\\ %& GPA 3.55
\end{tabular}

\section*{Experience}
\begin{longtable}{L!{\VRule}R}
2017--Present&{\bf Postdoctoral Research Scientist, Columbia University}\\
& Supervisors: Profs. Raul Rabadan, Chris Wiggins, and David Blei.\\\\
% & Machine learning and statistics for cancer genomics.\\\\
2011--2017&{\bf Graduate Research Assistant, UT Austin}\\
& Advisor: Prof. James G. Scott.\\\\
% & Focused on high-dimensional inference problems in machine learning.\\\\
2016 & {\bf Visiting Researcher, Duke University}\\
& Supervisor: Prof. Lawerence Carin\\\\
% & Investigated scalable Bayesian methods.\\\\
2015 & {\bf Visiting Researcher, Stanford University}\\
& Supervisor: Prof. Russell Poldrack\\\\
% & Worked on large-scale multiple hypothesis testing techniques for fMRI data.\\\\
2014 & {\bf Data Science Intern, MyFitnessPal}\\
% & Statistical modeling of millions of nutritional diaries.\\
% & Created large-scale inference experiments to predict user weight-loss success.\\\\
2013--2014 & {\bf Machine Learning Consultant, Atlas Wearables}\\
% & Designed initial exercise recognition algorithm for a new smart watch.\\
% & Brought a working product to market with excellent recognition performance in the real world.\\\\
2013 & {\bf Software Engineering Intern, Google}\\
% & Researched how to improve automated auction bidding.\\
% & Implemented and evaluated alternative bidding strategy experiments on massive datasets.\\\\
2011--2014 & {\bf Teaching Assistant, Computer Science Department, UT Austin}\\
% & Participated in developing course materials for hundreds of students.\\
% & Helped setup up competition for AI MOOC class taught by Peter Norvig. Directly managed team of four undergrad researchers.\\\\
2011--2012 & {\bf Co-founder, Curvio (Tech Startup)}\\
% & Built, launched, and iterated a consumer web startup.\\
% & Organically grew site to 2k uniques/day. Managed a team of 12 remote contractors and hundreds of turkers.\\\\
2010 & {\bf Co-founder, EffectCheck (Tech Startup)}\\
% & Created novel machine learning algorithms for sentiment analysis.\\
% & Worked all areas of the business: front-end, back-end, sales, partnerships, and marketing.\\\\
2010--2011 &\textbf{Machine Learning Consultant, Natural Selection Financial}\\
 % & Researched adaptive machine learning models for quantitative finance.\\
 % & Developed algorithms that explore huge data sets and discover exploitable patterns in market prices.\\\\
2008--2010 & \textbf{Quantitative Research Associate, Lincoln Vale Adaptive Strategies (Hedge Fund)}\\
     % & Researched and implemented machine learning algorithms for automated trading.\\
     % & Developed 20+ real-world trading algorithms, with millions of dollars wagered on their predictions every day.\\
\end{longtable}

% \bibliographystyle{plain}
% \nobibliography{pubs}
\bibliographystyle{abbrvnat}
\nobibliography{pubs}
\section*{Publications}
\begin{longtable}{L!{\VRule}R}
2018&\bibentry{tansey:etal:icml:2018:bbfdr}.\vspace{5pt}\\
2018&\bibentry{tansey:etal:aaai:2018:leafsmoothing}.\vspace{5pt}\\
2018&\bibentry{tansey:etal:aaai:2018:crispier}.\vspace{5pt}\\
2017&\bibentry{tansey:etal:fdrsmoothing:2017}.\vspace{5pt}\\
2017&\bibentry{tansey:etal:spatialdensity:2017}.\vspace{5pt}\\
2016&\bibentry{tansey:etal:nips:2016}.\vspace{5pt}\\
2015&\bibentry{tansey:etal:icml:2015}.\vspace{5pt}\\
2012&\bibentry{miikkulainen:etal:2012}.\vspace{5pt}\\
2012&\bibentry{tansey:etal:2012}.\vspace{5pt}\\
2009&\bibentry{song:etal:2009}.\vspace{5pt}\\
2008&\bibentry{tansey:tilevich:oopsla:2008}.\vspace{5pt}\\
2008&\bibentry{tansey:tilevich:ipdps:2008}.\vspace{5pt}\\
2008&\bibentry{gopal:etal:2008}.\\
\end{longtable}

\section*{Professional Service}
\begin{longtable}{L!{\VRule}R}
& Co-organizer: 2018 ICML Workshop on Computational Biology \\
& Reviewer: JASA (Theory \& Methods), AoAS, JMLR, NIPS \\
& Intellectual Entrepreneurship pre-grad mentor
\end{longtable}

\section*{Presentations and Talks}
\begin{longtable}{L!{\VRule}R}
& ``Black Box FDR''; ICML'18; Stockholm, Sweden; 2018 \\\\
& ``Predictive Modeling of Treatment Efficacy in Cancer Cell Lines''; Department of Statistics, University of Texas at Austin; Austin, TX; 2018 \\\\
& ``Diet2Vec: Multi-scale Analysis of Massive Dietary Data''; NIPS Workshop on Machine Learning for Health (poster); Barcelona, Spain; 2016 \\\\
& ``False Discovery Rate Smoothing''; Joint Statistical Meetings; Seattle, WA; 2015 \\\\
& ``Vector-space MRFs via Exponential Families''; The 32nd International Conference on Machine Learning; Lille, France; 2015 \\\\
& ``False Discovery Rate Smoothing''; ISBA Nonparametric Bayes; Raleigh, NC; 2015 \\\\
& ``Accelerating Evolution via Egalitarian Social Learning''; International Conference on Genetic and Evolutionary Computation Conference; Philadelphia, PA; 2012 \\\\
& ``Annotation Refactoring: Inferring Upgrade Transformations for Legacy Applications''; 24th ACM SIGPLAN Conference on Object Oriented Programming Systems, Languages, and Applications; Nashville, TN; 2009 \\\\
& ``Efficient Automated Marshaling of C++ Data Structures for MPI Applications''; IEEE International Symposium on Parallel and Distributed Processing; Miami, FL; 2008 \\
\end{longtable}

\section*{Awards and Miscellanea}
\begin{longtable}{L!{\VRule}R}
& Columbia Data Science Institute Seed Funds Grant: \$200K to develop personalized cancer therapies using deep probabilistic models\\\\
& 2x Recipient of the Garg Fellowship for Research with Real-World Impact\\\\
& Recipient of NSF Beacon Grant\\\\
& NSF Graduate Research Fellowship Program, Honorable Mention in Machine Learning\\\\
& Outstanding Graduate Student Award, Virginia Tech\\\\
& Projects available on my website: \url{http://cs.utexas.edu/~tansey}
\end{longtable}

\end{document}